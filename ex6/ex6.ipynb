{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVSDMhfRu_eX"
      },
      "source": [
        "# Ensemble Machine Learning Algorithms in Python with scikit-learn\n",
        "\n",
        "> Ensembles can give you a boost in accuracy on your dataset.\n",
        "![0_yMbDVA-mPWvzFXCM.png](attachment:0_yMbDVA-mPWvzFXCM.png)\n",
        "> In this notebook you will discover how you can create some of the most powerful types of ensembles in Python using scikit-learn.\n",
        "\n",
        "# Combine Model Predictions Into Ensemble Predictions\n",
        "\n",
        "The three most popular methods for combining the predictions from different models are:\n",
        "\n",
        "- **Bagging**. Building multiple models (typically of the same type) from different subsamples of the training dataset.\n",
        "- **Boosting**. Building multiple models (typically of the same type) each of which learns to fix the prediction errors of a prior model in the chain.\n",
        "- **Voting**. Building multiple models (typically of differing types) and simple statistics (like calculating the mean) are used to combine predictions.\n",
        "\n",
        "***\n",
        "\n",
        "A standard classification problem used to demonstrate each ensemble algorithm is the Pima Indians onset of diabetes dataset. It is a binary classification problem where all of the input variables are numeric and have differing scales.\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRKXcclmu_ez"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:18.957033Z",
          "iopub.status.busy": "2022-02-05T22:49:18.956732Z",
          "iopub.status.idle": "2022-02-05T22:49:19.941241Z",
          "shell.execute_reply": "2022-02-05T22:49:19.940234Z",
          "shell.execute_reply.started": "2022-02-05T22:49:18.956995Z"
        },
        "id": "_i2Ke-FYu_fS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.style.use(\"fivethirtyeight\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l7N01Mlu_fY"
      },
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:19.944032Z",
          "iopub.status.busy": "2022-02-05T22:49:19.943472Z",
          "iopub.status.idle": "2022-02-05T22:49:19.992990Z",
          "shell.execute_reply": "2022-02-05T22:49:19.992011Z",
          "shell.execute_reply.started": "2022-02-05T22:49:19.943972Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "UllHgBvLu_fa",
        "outputId": "ba17f997-6631-4d7f-cf18-437914318037"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49dc0549-0d49-44b1-beba-37cacfaa9fec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49dc0549-0d49-44b1-beba-37cacfaa9fec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49dc0549-0d49-44b1-beba-37cacfaa9fec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49dc0549-0d49-44b1-beba-37cacfaa9fec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "df = pd.read_csv(\"../input/diabetes.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:19.995020Z",
          "iopub.status.busy": "2022-02-05T22:49:19.994491Z",
          "iopub.status.idle": "2022-02-05T22:49:20.007879Z",
          "shell.execute_reply": "2022-02-05T22:49:20.006866Z",
          "shell.execute_reply.started": "2022-02-05T22:49:19.994963Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ik9RT-Asu_gD",
        "outputId": "37d89df4-ecf5-423d-9a3f-b0c9e8e5042d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 768 entries, 0 to 767\n",
            "Data columns (total 9 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Pregnancies               768 non-null    int64  \n",
            " 1   Glucose                   768 non-null    int64  \n",
            " 2   BloodPressure             768 non-null    int64  \n",
            " 3   SkinThickness             768 non-null    int64  \n",
            " 4   Insulin                   768 non-null    int64  \n",
            " 5   BMI                       768 non-null    float64\n",
            " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
            " 7   Age                       768 non-null    int64  \n",
            " 8   Outcome                   768 non-null    int64  \n",
            "dtypes: float64(2), int64(7)\n",
            "memory usage: 54.1 KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:20.010473Z",
          "iopub.status.busy": "2022-02-05T22:49:20.009821Z",
          "iopub.status.idle": "2022-02-05T22:49:20.020062Z",
          "shell.execute_reply": "2022-02-05T22:49:20.018983Z",
          "shell.execute_reply.started": "2022-02-05T22:49:20.010415Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a_7rApeu_gF",
        "outputId": "77855673-2bd2-4cce-869e-be2fb5467821"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pregnancies                 0\n",
              "Glucose                     0\n",
              "BloodPressure               0\n",
              "SkinThickness               0\n",
              "Insulin                     0\n",
              "BMI                         0\n",
              "DiabetesPedigreeFunction    0\n",
              "Age                         0\n",
              "Outcome                     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:20.023886Z",
          "iopub.status.busy": "2022-02-05T22:49:20.023348Z",
          "iopub.status.idle": "2022-02-05T22:49:20.072463Z",
          "shell.execute_reply": "2022-02-05T22:49:20.071358Z",
          "shell.execute_reply.started": "2022-02-05T22:49:20.023820Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "uZ7hLRkKu_gI",
        "outputId": "9969838e-6687-4ea2-efed-985a4409ab8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin    BMI  \\\n",
              "count       768.00   768.00         768.00         768.00   768.00 768.00   \n",
              "mean          3.85   120.89          69.11          20.54    79.80  31.99   \n",
              "std           3.37    31.97          19.36          15.95   115.24   7.88   \n",
              "min           0.00     0.00           0.00           0.00     0.00   0.00   \n",
              "25%           1.00    99.00          62.00           0.00     0.00  27.30   \n",
              "50%           3.00   117.00          72.00          23.00    30.50  32.00   \n",
              "75%           6.00   140.25          80.00          32.00   127.25  36.60   \n",
              "max          17.00   199.00         122.00          99.00   846.00  67.10   \n",
              "\n",
              "       DiabetesPedigreeFunction    Age  Outcome  \n",
              "count                    768.00 768.00   768.00  \n",
              "mean                       0.47  33.24     0.35  \n",
              "std                        0.33  11.76     0.48  \n",
              "min                        0.08  21.00     0.00  \n",
              "25%                        0.24  24.00     0.00  \n",
              "50%                        0.37  29.00     0.00  \n",
              "75%                        0.63  41.00     1.00  \n",
              "max                        2.42  81.00     1.00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d5ff6b3-10fd-449b-a488-1366da76f632\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>768.00</td>\n",
              "      <td>768.00</td>\n",
              "      <td>768.00</td>\n",
              "      <td>768.00</td>\n",
              "      <td>768.00</td>\n",
              "      <td>768.00</td>\n",
              "      <td>768.00</td>\n",
              "      <td>768.00</td>\n",
              "      <td>768.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.85</td>\n",
              "      <td>120.89</td>\n",
              "      <td>69.11</td>\n",
              "      <td>20.54</td>\n",
              "      <td>79.80</td>\n",
              "      <td>31.99</td>\n",
              "      <td>0.47</td>\n",
              "      <td>33.24</td>\n",
              "      <td>0.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.37</td>\n",
              "      <td>31.97</td>\n",
              "      <td>19.36</td>\n",
              "      <td>15.95</td>\n",
              "      <td>115.24</td>\n",
              "      <td>7.88</td>\n",
              "      <td>0.33</td>\n",
              "      <td>11.76</td>\n",
              "      <td>0.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.08</td>\n",
              "      <td>21.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.00</td>\n",
              "      <td>99.00</td>\n",
              "      <td>62.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>27.30</td>\n",
              "      <td>0.24</td>\n",
              "      <td>24.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.00</td>\n",
              "      <td>117.00</td>\n",
              "      <td>72.00</td>\n",
              "      <td>23.00</td>\n",
              "      <td>30.50</td>\n",
              "      <td>32.00</td>\n",
              "      <td>0.37</td>\n",
              "      <td>29.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.00</td>\n",
              "      <td>140.25</td>\n",
              "      <td>80.00</td>\n",
              "      <td>32.00</td>\n",
              "      <td>127.25</td>\n",
              "      <td>36.60</td>\n",
              "      <td>0.63</td>\n",
              "      <td>41.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.00</td>\n",
              "      <td>199.00</td>\n",
              "      <td>122.00</td>\n",
              "      <td>99.00</td>\n",
              "      <td>846.00</td>\n",
              "      <td>67.10</td>\n",
              "      <td>2.42</td>\n",
              "      <td>81.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d5ff6b3-10fd-449b-a488-1366da76f632')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d5ff6b3-10fd-449b-a488-1366da76f632 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d5ff6b3-10fd-449b-a488-1366da76f632');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "pd.set_option('display.float_format', '{:.2f}'.format)\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:20.076419Z",
          "iopub.status.busy": "2022-02-05T22:49:20.075960Z",
          "iopub.status.idle": "2022-02-05T22:49:20.105803Z",
          "shell.execute_reply": "2022-02-05T22:49:20.104732Z",
          "shell.execute_reply.started": "2022-02-05T22:49:20.076334Z"
        },
        "id": "u1sSeX7Cu_gm"
      },
      "outputs": [],
      "source": [
        "categorical_val = []\n",
        "continous_val = []\n",
        "for column in df.columns:\n",
        "#     print('==============================')\n",
        "#     print(f\"{column} : {df[column].unique()}\")\n",
        "    if len(df[column].unique()) <= 10:\n",
        "        categorical_val.append(column)\n",
        "    else:\n",
        "        continous_val.append(column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di6v4SOBu_gq"
      },
      "source": [
        "# Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:20.107983Z",
          "iopub.status.busy": "2022-02-05T22:49:20.107424Z",
          "iopub.status.idle": "2022-02-05T22:49:20.115175Z",
          "shell.execute_reply": "2022-02-05T22:49:20.114221Z",
          "shell.execute_reply.started": "2022-02-05T22:49:20.107922Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ry-EuF7u_gs",
        "outputId": "69a83544-7b4c-4336-a2ad-c6494a8e678e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
              "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:20.116884Z",
          "iopub.status.busy": "2022-02-05T22:49:20.116476Z",
          "iopub.status.idle": "2022-02-05T22:49:20.144418Z",
          "shell.execute_reply": "2022-02-05T22:49:20.143451Z",
          "shell.execute_reply.started": "2022-02-05T22:49:20.116842Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuLaMAFuu_gt",
        "outputId": "28f97728-2a21-4b48-da8b-cb07ab4f60d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================\n",
            "Pregnancies ==> Missing zeros : 111\n",
            "============================================\n",
            "Glucose ==> Missing zeros : 5\n",
            "============================================\n",
            "BloodPressure ==> Missing zeros : 35\n",
            "============================================\n",
            "SkinThickness ==> Missing zeros : 227\n",
            "============================================\n",
            "Insulin ==> Missing zeros : 374\n",
            "============================================\n",
            "BMI ==> Missing zeros : 11\n",
            "============================================\n",
            "DiabetesPedigreeFunction ==> Missing zeros : 0\n",
            "============================================\n",
            "Age ==> Missing zeros : 0\n"
          ]
        }
      ],
      "source": [
        "# How many missing zeros are mising in each feature\n",
        "feature_columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
        "for column in feature_columns:\n",
        "    print(\"============================================\")\n",
        "    print(f\"{column} ==> Missing zeros : {len(df.loc[df[column] == 0])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:20.146417Z",
          "iopub.status.busy": "2022-02-05T22:49:20.146050Z",
          "iopub.status.idle": "2022-02-05T22:49:20.207250Z",
          "shell.execute_reply": "2022-02-05T22:49:20.206488Z",
          "shell.execute_reply.started": "2022-02-05T22:49:20.146348Z"
        },
        "id": "YtI-p1fqu_gy"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "fill_values = SimpleImputer(missing_values=0, strategy=\"mean\", copy=False)\n",
        "\n",
        "df[feature_columns] = fill_values.fit_transform(df[feature_columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:20.208869Z",
          "iopub.status.busy": "2022-02-05T22:49:20.208448Z",
          "iopub.status.idle": "2022-02-05T22:49:20.227832Z",
          "shell.execute_reply": "2022-02-05T22:49:20.226442Z",
          "shell.execute_reply.started": "2022-02-05T22:49:20.208799Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siUaRp21u_g0",
        "outputId": "3a9f1f7f-5797-4283-986f-f066985cefb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================\n",
            "Pregnancies ==> Missing zeros : 0\n",
            "============================================\n",
            "Glucose ==> Missing zeros : 0\n",
            "============================================\n",
            "BloodPressure ==> Missing zeros : 0\n",
            "============================================\n",
            "SkinThickness ==> Missing zeros : 0\n",
            "============================================\n",
            "Insulin ==> Missing zeros : 0\n",
            "============================================\n",
            "BMI ==> Missing zeros : 0\n",
            "============================================\n",
            "DiabetesPedigreeFunction ==> Missing zeros : 0\n",
            "============================================\n",
            "Age ==> Missing zeros : 0\n"
          ]
        }
      ],
      "source": [
        "for column in feature_columns:\n",
        "    print(\"============================================\")\n",
        "    print(f\"{column} ==> Missing zeros : {len(df.loc[df[column] == 0])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:24.314664Z",
          "iopub.status.busy": "2022-02-05T22:49:24.314226Z",
          "iopub.status.idle": "2022-02-05T22:49:25.019624Z",
          "shell.execute_reply": "2022-02-05T22:49:25.017914Z",
          "shell.execute_reply.started": "2022-02-05T22:49:24.314589Z"
        },
        "id": "9e2Fz-epu_g2"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X = df[feature_columns]\n",
        "y = df.Outcome\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:25.021817Z",
          "iopub.status.busy": "2022-02-05T22:49:25.021280Z",
          "iopub.status.idle": "2022-02-05T22:49:25.031499Z",
          "shell.execute_reply": "2022-02-05T22:49:25.030393Z",
          "shell.execute_reply.started": "2022-02-05T22:49:25.021758Z"
        },
        "id": "_ELVfLxSu_g3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "\n",
        "def evaluate(model, X_train, X_test, y_train, y_test):\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    y_train_pred = model.predict(X_train)\n",
        "\n",
        "    print(\"TRAINIG RESULTS: \\n===============================\")\n",
        "    clf_report = pd.DataFrame(classification_report(y_train, y_train_pred, output_dict=True))\n",
        "    print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_train, y_train_pred)}\")\n",
        "    print(f\"ACCURACY SCORE:\\n{accuracy_score(y_train, y_train_pred):.4f}\")\n",
        "    print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
        "\n",
        "    print(\"TESTING RESULTS: \\n===============================\")\n",
        "    clf_report = pd.DataFrame(classification_report(y_test, y_test_pred, output_dict=True))\n",
        "    print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_test, y_test_pred)}\")\n",
        "    print(f\"ACCURACY SCORE:\\n{accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "    print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvOs7idQu_g5"
      },
      "source": [
        "# Bagging Algorithms\n",
        "Bootstrap Aggregation or bagging involves taking multiple samples from your training dataset (with replacement) and training a model for each sample.\n",
        "\n",
        "The final output prediction is averaged across the predictions of all of the sub-models.\n",
        "\n",
        "The three bagging models covered in this section are as follows:\n",
        "\n",
        "1. Bagged Decision Trees\n",
        "2. Random Forest\n",
        "3. Extra Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nQoWVSFu_g7"
      },
      "source": [
        "## 1. Bagged Decision Trees\n",
        "Bagging performs best with algorithms that have high variance. A popular example are decision trees, often constructed without pruning.\n",
        "\n",
        "**BaggingClassifier**:\n",
        "\n",
        "A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it.\n",
        "\n",
        "This algorithm encompasses several works from the literature. When random subsets of the dataset are drawn as random subsets of the samples, then this algorithm is known as Pasting. If samples are drawn with replacement, then the method is known as Bagging. When random subsets of the dataset are drawn as random subsets of the features, then the method is known as Random Subspaces. Finally, when base estimators are built on subsets of both samples and features, then the method is known as Random Patches.\n",
        "\n",
        "**BaggingClassifier Parameters:**\n",
        "- `base_estimator` : The base estimator to fit on random subsets of the dataset. If None, then the base estimator is a decision tree.\n",
        "***\n",
        "- `n_estimators` : The number of base estimators in the ensemble.\n",
        "***\n",
        "- `max_samples` : The number of samples to draw from X to train each base estimator.\n",
        "***\n",
        "- `max_features` : The number of features to draw from X to train each base estimator.\n",
        "***\n",
        "- `bootstrap` : Whether samples are drawn with replacement. If False, sampling without replacement is performed.\n",
        "***\n",
        "- `bootstrap_features` : Whether features are drawn with replacement.\n",
        "***\n",
        "- `oob_score` : Whether to use out-of-bag samples to estimate the generalization error.\n",
        "***\n",
        "- `warm_start` : When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:25.033662Z",
          "iopub.status.busy": "2022-02-05T22:49:25.033249Z",
          "iopub.status.idle": "2022-02-05T22:49:28.921053Z",
          "shell.execute_reply": "2022-02-05T22:49:28.920141Z",
          "shell.execute_reply.started": "2022-02-05T22:49:25.033552Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsrbvWlsu_g_",
        "outputId": "de68e80e-8394-406e-de28-e0478b0e908f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINIG RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[349   0]\n",
            " [  0 188]]\n",
            "ACCURACY SCORE:\n",
            "1.0000\n",
            "CLASSIFICATION REPORT:\n",
            "               0      1  accuracy  macro avg  weighted avg\n",
            "precision   1.00   1.00      1.00       1.00          1.00\n",
            "recall      1.00   1.00      1.00       1.00          1.00\n",
            "f1-score    1.00   1.00      1.00       1.00          1.00\n",
            "support   349.00 188.00      1.00     537.00        537.00\n",
            "TESTING RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[119  32]\n",
            " [ 24  56]]\n",
            "ACCURACY SCORE:\n",
            "0.7576\n",
            "CLASSIFICATION REPORT:\n",
            "               0     1  accuracy  macro avg  weighted avg\n",
            "precision   0.83  0.64      0.76       0.73          0.76\n",
            "recall      0.79  0.70      0.76       0.74          0.76\n",
            "f1-score    0.81  0.67      0.76       0.74          0.76\n",
            "support   151.00 80.00      0.76     231.00        231.00\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree = DecisionTreeClassifier()\n",
        "bagging_clf = BaggingClassifier(base_estimator=tree, n_estimators=1500, random_state=42)\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "evaluate(bagging_clf, X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:28.922604Z",
          "iopub.status.busy": "2022-02-05T22:49:28.922361Z",
          "iopub.status.idle": "2022-02-05T22:49:29.325499Z",
          "shell.execute_reply": "2022-02-05T22:49:29.324528Z",
          "shell.execute_reply.started": "2022-02-05T22:49:28.922561Z"
        },
        "id": "SL0fvefWu_hC"
      },
      "outputs": [],
      "source": [
        "scores = {\n",
        "    'Bagging Classifier': {\n",
        "        'Train': accuracy_score(y_train, bagging_clf.predict(X_train)),\n",
        "        'Test': accuracy_score(y_test, bagging_clf.predict(X_test)),\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EHc--ysu_hD"
      },
      "source": [
        "## 2. Random Forest\n",
        "\n",
        "A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.\n",
        "\n",
        "The sub-sample size is always the same as the original input sample size but the samples are drawn with replacement if `bootstrap=True` (default).\n",
        "\n",
        "- **Random forest algorithm parameters:**\n",
        "- `n_estimators`: The number of trees in the forest.\n",
        "*** \n",
        "- `criterion`: The function to measure the quality of a split. Supported criteria are \"`gini`\" for the Gini impurity and \"`entropy`\" for the information gain.\n",
        "***\n",
        "- `max_depth`: The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than `min_samples_split` samples.\n",
        "***\n",
        "- `min_samples_split`: The minimum number of samples required to split an internal node.\n",
        "***\n",
        "- `min_samples_leaf`: The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least ``min_samples_leaf`` training samples in each of the left and right branches.  This may have the effect of smoothing the model, especially in regression.\n",
        "***\n",
        "- `min_weight_fraction_leaf`: The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.\n",
        "***\n",
        "- `max_features`: The number of features to consider when looking for the best split.\n",
        "***\n",
        "- `max_leaf_nodes`: Grow a tree with ``max_leaf_nodes`` in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.\n",
        "***\n",
        "- `min_impurity_decrease`: A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
        "***\n",
        "- `min_impurity_split`: Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.\n",
        "***\n",
        "- `bootstrap`: Whether bootstrap samples are used when building trees. If False, the whole datset is used to build each tree.\n",
        "***\n",
        "- `oob_score`: Whether to use out-of-bag samples to estimate the generalization accuracy.\n",
        "***\n",
        "- `warm_start` : When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:29.327181Z",
          "iopub.status.busy": "2022-02-05T22:49:29.326894Z",
          "iopub.status.idle": "2022-02-05T22:49:30.993898Z",
          "shell.execute_reply": "2022-02-05T22:49:30.993147Z",
          "shell.execute_reply.started": "2022-02-05T22:49:29.327130Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzot7PnPu_hF",
        "outputId": "6da70890-4111-4600-f3db-9bbc715867a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINIG RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[349   0]\n",
            " [  0 188]]\n",
            "ACCURACY SCORE:\n",
            "1.0000\n",
            "CLASSIFICATION REPORT:\n",
            "               0      1  accuracy  macro avg  weighted avg\n",
            "precision   1.00   1.00      1.00       1.00          1.00\n",
            "recall      1.00   1.00      1.00       1.00          1.00\n",
            "f1-score    1.00   1.00      1.00       1.00          1.00\n",
            "support   349.00 188.00      1.00     537.00        537.00\n",
            "TESTING RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[123  28]\n",
            " [ 29  51]]\n",
            "ACCURACY SCORE:\n",
            "0.7532\n",
            "CLASSIFICATION REPORT:\n",
            "               0     1  accuracy  macro avg  weighted avg\n",
            "precision   0.81  0.65      0.75       0.73          0.75\n",
            "recall      0.81  0.64      0.75       0.73          0.75\n",
            "f1-score    0.81  0.64      0.75       0.73          0.75\n",
            "support   151.00 80.00      0.75     231.00        231.00\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_clf = RandomForestClassifier(random_state=42, n_estimators=1000)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "evaluate(rf_clf, X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:30.995752Z",
          "iopub.status.busy": "2022-02-05T22:49:30.995459Z",
          "iopub.status.idle": "2022-02-05T22:49:31.235197Z",
          "shell.execute_reply": "2022-02-05T22:49:31.234222Z",
          "shell.execute_reply.started": "2022-02-05T22:49:30.995702Z"
        },
        "id": "I45Or2j2u_hH"
      },
      "outputs": [],
      "source": [
        "scores['Random Forest'] = {\n",
        "        'Train': accuracy_score(y_train, rf_clf.predict(X_train)),\n",
        "        'Test': accuracy_score(y_test, rf_clf.predict(X_test)),\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6L7n3Bsu_hI"
      },
      "source": [
        "## 3. Extra Trees\n",
        "Extra Trees are another modification of bagging where random trees are constructed from samples of the training dataset.\n",
        "\n",
        "You can construct an Extra Trees model for classification using the ExtraTreesClassifier class.\n",
        "\n",
        "**ExtraTreeClassifier**:\n",
        "\n",
        "This class implements a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.\n",
        "\n",
        "**ExtraTreeClassifier Parameters**:\n",
        "- `n_estimators`: The number of trees in the forest.\n",
        "*** \n",
        "- `criterion`: The function to measure the quality of a split. Supported criteria are \"`gini`\" for the Gini impurity and \"`entropy`\" for the information gain.\n",
        "***\n",
        "- `max_depth`: The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than `min_samples_split` samples.\n",
        "***\n",
        "- `min_samples_split`: The minimum number of samples required to split an internal node.\n",
        "***\n",
        "- `min_samples_leaf`: The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least ``min_samples_leaf`` training samples in each of the left and right branches.  This may have the effect of smoothing the model, especially in regression.\n",
        "***\n",
        "- `min_weight_fraction_leaf`: The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.\n",
        "***\n",
        "- `max_features`: The number of features to consider when looking for the best split.\n",
        "***\n",
        "- `max_leaf_nodes`: Grow a tree with ``max_leaf_nodes`` in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.\n",
        "***\n",
        "- `min_impurity_decrease`: A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
        "***\n",
        "- `min_impurity_split`: Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.\n",
        "***\n",
        "- `bootstrap`: Whether bootstrap samples are used when building trees. If False, the whole datset is used to build each tree.\n",
        "***\n",
        "- `oob_score`: Whether to use out-of-bag samples to estimate the generalization accuracy.\n",
        "***\n",
        "- `warm_start` : When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:31.237210Z",
          "iopub.status.busy": "2022-02-05T22:49:31.236936Z",
          "iopub.status.idle": "2022-02-05T22:49:32.821234Z",
          "shell.execute_reply": "2022-02-05T22:49:32.820376Z",
          "shell.execute_reply.started": "2022-02-05T22:49:31.237159Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWpFMMEtu_hK",
        "outputId": "047f76b8-9558-4bff-acba-44fda8021d7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINIG RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[349   0]\n",
            " [  0 188]]\n",
            "ACCURACY SCORE:\n",
            "1.0000\n",
            "CLASSIFICATION REPORT:\n",
            "               0      1  accuracy  macro avg  weighted avg\n",
            "precision   1.00   1.00      1.00       1.00          1.00\n",
            "recall      1.00   1.00      1.00       1.00          1.00\n",
            "f1-score    1.00   1.00      1.00       1.00          1.00\n",
            "support   349.00 188.00      1.00     537.00        537.00\n",
            "TESTING RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[124  27]\n",
            " [ 25  55]]\n",
            "ACCURACY SCORE:\n",
            "0.7749\n",
            "CLASSIFICATION REPORT:\n",
            "               0     1  accuracy  macro avg  weighted avg\n",
            "precision   0.83  0.67      0.77       0.75          0.78\n",
            "recall      0.82  0.69      0.77       0.75          0.77\n",
            "f1-score    0.83  0.68      0.77       0.75          0.78\n",
            "support   151.00 80.00      0.77     231.00        231.00\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "ex_tree_clf = ExtraTreesClassifier(n_estimators=1000, max_features=7, random_state=42)\n",
        "ex_tree_clf.fit(X_train, y_train)\n",
        "evaluate(ex_tree_clf, X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:32.823000Z",
          "iopub.status.busy": "2022-02-05T22:49:32.822717Z",
          "iopub.status.idle": "2022-02-05T22:49:33.085105Z",
          "shell.execute_reply": "2022-02-05T22:49:33.084253Z",
          "shell.execute_reply.started": "2022-02-05T22:49:32.822950Z"
        },
        "id": "Ci3_RY6Zu_hL"
      },
      "outputs": [],
      "source": [
        "scores['Extra Tree'] = {\n",
        "        'Train': accuracy_score(y_train, ex_tree_clf.predict(X_train)),\n",
        "        'Test': accuracy_score(y_test, ex_tree_clf.predict(X_test)),\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIoLk_xvu_hO"
      },
      "source": [
        "# Boosting Algorithms\n",
        "Boosting ensemble algorithms creates a sequence of models that attempt to correct the mistakes of the models before them in the sequence.\n",
        "\n",
        "Once created, the models make predictions which may be weighted by their demonstrated accuracy and the results are combined to create a final output prediction.\n",
        "\n",
        "The two most common boosting ensemble machine learning algorithms are:\n",
        "\n",
        "1. AdaBoost\n",
        "2. Stochastic Gradient Boosting\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXBq7BdPu_hP"
      },
      "source": [
        "## 1. AdaBoost\n",
        "AdaBoost was perhaps the first successful boosting ensemble algorithm. It generally works by weighting instances in the dataset by how easy or difficult they are to classify, allowing the algorithm to pay or or less attention to them in the construction of subsequent models.\n",
        "\n",
        "You can construct an AdaBoost model for classification using the AdaBoostClassifier class.\n",
        "\n",
        "**AdaBoostClassifier**:\n",
        "\n",
        "An AdaBoost classifier is a meta-estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases.\n",
        "\n",
        "**AdaBoostClassifier Params**:\n",
        "- `base_estimator` : The base estimator from which the boosted ensemble is built.\n",
        "***\n",
        "- `n_estimators` : The maximum number of estimators at which boosting is terminated. In case of perfect fit, the learning procedure is stopped early.\n",
        "***\n",
        "- `learning_rate` : Learning rate shrinks the contribution of each classifier by ``learning_rate``. There is a trade-off between ``learning_rate`` and ``n_estimators``.\n",
        "***\n",
        "- `algorithm` : If 'SAMME.R' then use the SAMME.R real boosting algorithm. ``base_estimator`` must support calculation of class probabilities. If 'SAMME' then use the SAMME discrete boosting algorithm. The SAMME.R algorithm typically converges faster than SAMME, achieving a lower test error with fewer boosting iterations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:33.086950Z",
          "iopub.status.busy": "2022-02-05T22:49:33.086665Z",
          "iopub.status.idle": "2022-02-05T22:49:33.173216Z",
          "shell.execute_reply": "2022-02-05T22:49:33.172299Z",
          "shell.execute_reply.started": "2022-02-05T22:49:33.086899Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJ-_Z-CUu_hS",
        "outputId": "8bec204c-834c-43b3-bfb8-00790414fe43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINIG RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[310  39]\n",
            " [ 51 137]]\n",
            "ACCURACY SCORE:\n",
            "0.8324\n",
            "CLASSIFICATION REPORT:\n",
            "               0      1  accuracy  macro avg  weighted avg\n",
            "precision   0.86   0.78      0.83       0.82          0.83\n",
            "recall      0.89   0.73      0.83       0.81          0.83\n",
            "f1-score    0.87   0.75      0.83       0.81          0.83\n",
            "support   349.00 188.00      0.83     537.00        537.00\n",
            "TESTING RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[123  28]\n",
            " [ 27  53]]\n",
            "ACCURACY SCORE:\n",
            "0.7619\n",
            "CLASSIFICATION REPORT:\n",
            "               0     1  accuracy  macro avg  weighted avg\n",
            "precision   0.82  0.65      0.76       0.74          0.76\n",
            "recall      0.81  0.66      0.76       0.74          0.76\n",
            "f1-score    0.82  0.66      0.76       0.74          0.76\n",
            "support   151.00 80.00      0.76     231.00        231.00\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_boost_clf = AdaBoostClassifier(n_estimators=30)\n",
        "ada_boost_clf.fit(X_train, y_train)\n",
        "evaluate(ada_boost_clf, X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:33.174924Z",
          "iopub.status.busy": "2022-02-05T22:49:33.174624Z",
          "iopub.status.idle": "2022-02-05T22:49:33.194529Z",
          "shell.execute_reply": "2022-02-05T22:49:33.193739Z",
          "shell.execute_reply.started": "2022-02-05T22:49:33.174871Z"
        },
        "id": "nbgHHwBTu_hT"
      },
      "outputs": [],
      "source": [
        "scores['AdaBoost'] = {\n",
        "        'Train': accuracy_score(y_train, ada_boost_clf.predict(X_train)),\n",
        "        'Test': accuracy_score(y_test, ada_boost_clf.predict(X_test)),\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO59noK_u_hU"
      },
      "source": [
        "## 2. Stochastic Gradient Boosting\n",
        "Stochastic Gradient Boosting (also called Gradient Boosting Machines) are one of the most sophisticated ensemble techniques. It is also a technique that is proving to be perhaps of the the best techniques available for improving performance via ensembles.\n",
        "\n",
        "**GradientBoostingClassifier**:\n",
        "\n",
        "GB builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. In each stage ``n_classes_`` regression trees are fit on the negative gradient of the binomial or multinomial deviance loss function. Binary classification is a special case where only a single regression tree is induced.\n",
        "\n",
        "**GradientBoostingClassifier Parameters**:\n",
        "\n",
        "- `loss` : loss function to be optimized. 'deviance' refers to deviance (= logistic regression) for classification with probabilistic outputs. For loss 'exponential' gradient boosting recovers the AdaBoost algorithm.\n",
        "***\n",
        "- `learning_rate` : learning rate shrinks the contribution of each tree by `learning_rate`. There is a trade-off between learning_rate and n_estimators.\n",
        "***\n",
        "- `n_estimators` : The number of boosting stages to perform. Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance.\n",
        "***\n",
        "- `subsample` : The fraction of samples to be used for fitting the individual base learners. If smaller than 1.0 this results in Stochastic Gradient Boosting. `subsample` interacts with the parameter `n_estimators`. Choosing `subsample < 1.0` leads to a reduction of variance and an increase in bias.\n",
        "***\n",
        "- `criterion` : The function to measure the quality of a split. Supported criteria are \"friedman_mse\" for the mean squared error with improvement score by Friedman, \"mse\" for mean squared error, and \"mae\" for the mean absolute error. The default value of \"friedman_mse\" is generally the best as it can provide a better approximation in some cases.\n",
        "***\n",
        "- `min_samples_split`: The minimum number of samples required to split an internal node.\n",
        "***\n",
        "- `min_samples_leaf`: The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least ``min_samples_leaf`` training samples in each of the left and right branches.  This may have the effect of smoothing the model, especially in regression.\n",
        "***\n",
        "- `min_weight_fraction_leaf`: The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.\n",
        "***\n",
        "- `max_depth`: maximum depth of the individual regression estimators. The maximum depth limits the number of nodes in the tree. Tune this parameter for best performance; the best value depends on the interaction of the input variables.\n",
        "***\n",
        "- `min_impurity_decrease`: A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
        "***\n",
        "- `min_impurity_split`: Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.\n",
        "***\n",
        "- `max_features`: The number of features to consider when looking for the best split.\n",
        "***\n",
        "- `max_leaf_nodes`: Grow trees with ``max_leaf_nodes`` in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.\n",
        "***\n",
        "- `warm_start`: When set to ``True``, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just erase the previous solution.\n",
        "***\n",
        "- `validation_fraction`: The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. Only used if ``n_iter_no_change`` is set to an integer.\n",
        "***\n",
        "- `n_iter_no_change`: used to decide if early stopping will be used to terminate training when validation score is not improving. By default it is set to None to disable early stopping. If set to a number, it will set aside ``validation_fraction`` size of the training data as validation and terminate training when validation score is not improving in all of the previous ``n_iter_no_change`` numbers of iterations. The split is stratified.\n",
        "***\n",
        "- `tol`: Tolerance for the early stopping. When the loss is not improving by at least tol for ``n_iter_no_change`` iterations (if set to a number), the training stops.\n",
        "***\n",
        "- `ccp_alpha`: Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than ``ccp_alpha`` will be chosen.\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:33.196248Z",
          "iopub.status.busy": "2022-02-05T22:49:33.195910Z",
          "iopub.status.idle": "2022-02-05T22:49:33.315792Z",
          "shell.execute_reply": "2022-02-05T22:49:33.315016Z",
          "shell.execute_reply.started": "2022-02-05T22:49:33.196185Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-EIUosWu_hV",
        "outputId": "e81cc8ab-51ef-43c9-ee5c-4d3546bd32ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINIG RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[342   7]\n",
            " [ 19 169]]\n",
            "ACCURACY SCORE:\n",
            "0.9516\n",
            "CLASSIFICATION REPORT:\n",
            "               0      1  accuracy  macro avg  weighted avg\n",
            "precision   0.95   0.96      0.95       0.95          0.95\n",
            "recall      0.98   0.90      0.95       0.94          0.95\n",
            "f1-score    0.96   0.93      0.95       0.95          0.95\n",
            "support   349.00 188.00      0.95     537.00        537.00\n",
            "TESTING RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[116  35]\n",
            " [ 26  54]]\n",
            "ACCURACY SCORE:\n",
            "0.7359\n",
            "CLASSIFICATION REPORT:\n",
            "               0     1  accuracy  macro avg  weighted avg\n",
            "precision   0.82  0.61      0.74       0.71          0.74\n",
            "recall      0.77  0.68      0.74       0.72          0.74\n",
            "f1-score    0.79  0.64      0.74       0.72          0.74\n",
            "support   151.00 80.00      0.74     231.00        231.00\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "grad_boost_clf = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "grad_boost_clf.fit(X_train, y_train)\n",
        "evaluate(grad_boost_clf, X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:33.317612Z",
          "iopub.status.busy": "2022-02-05T22:49:33.317347Z",
          "iopub.status.idle": "2022-02-05T22:49:33.328884Z",
          "shell.execute_reply": "2022-02-05T22:49:33.328019Z",
          "shell.execute_reply.started": "2022-02-05T22:49:33.317563Z"
        },
        "id": "5Afo_Ripu_hW"
      },
      "outputs": [],
      "source": [
        "scores['Gradient Boosting'] = {\n",
        "        'Train': accuracy_score(y_train, grad_boost_clf.predict(X_train)),\n",
        "        'Test': accuracy_score(y_test, grad_boost_clf.predict(X_test)),\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVDp_IPtu_hW"
      },
      "source": [
        "# Voting Ensemble\n",
        "\n",
        "Voting is one of the simplest ways of combining the predictions from multiple machine learning algorithms.\n",
        "\n",
        "It works by first creating two or more standalone models from your training dataset. A Voting Classifier can then be used to wrap your models and average the predictions of the sub-models when asked to make predictions for new data.\n",
        "\n",
        "The predictions of the sub-models can be weighted, but specifying the weights for classifiers manually or even heuristically is difficult. More advanced methods can learn how to best weight the predictions from submodels, but this is called stacking (stacked generalization) and is currently not provided in scikit-learn.\n",
        "\n",
        "**VotingClassifier** : \n",
        "- `estimators` : Invoking the ``fit`` method on the ``VotingClassifier`` will fit clones of those original estimators that will be stored in the class attribute ``self.estimators_``.\n",
        "***\n",
        "- `voting` : If 'hard', uses predicted class labels for majority rule voting. Else if 'soft', predicts the class label based on the argmax of the sums of the predicted probabilities, which is recommended for an ensemble of well-calibrated classifiers.\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:33.331568Z",
          "iopub.status.busy": "2022-02-05T22:49:33.331152Z",
          "iopub.status.idle": "2022-02-05T22:49:33.408760Z",
          "shell.execute_reply": "2022-02-05T22:49:33.408100Z",
          "shell.execute_reply.started": "2022-02-05T22:49:33.331483Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nkyNBmXu_hX",
        "outputId": "bb5f47ab-c3ad-478c-c899-ee3fa523089e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINIG RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[327  22]\n",
            " [ 82 106]]\n",
            "ACCURACY SCORE:\n",
            "0.8063\n",
            "CLASSIFICATION REPORT:\n",
            "               0      1  accuracy  macro avg  weighted avg\n",
            "precision   0.80   0.83      0.81       0.81          0.81\n",
            "recall      0.94   0.56      0.81       0.75          0.81\n",
            "f1-score    0.86   0.67      0.81       0.77          0.80\n",
            "support   349.00 188.00      0.81     537.00        537.00\n",
            "TESTING RESULTS: \n",
            "===============================\n",
            "CONFUSION MATRIX:\n",
            "[[131  20]\n",
            " [ 35  45]]\n",
            "ACCURACY SCORE:\n",
            "0.7619\n",
            "CLASSIFICATION REPORT:\n",
            "               0     1  accuracy  macro avg  weighted avg\n",
            "precision   0.79  0.69      0.76       0.74          0.76\n",
            "recall      0.87  0.56      0.76       0.72          0.76\n",
            "f1-score    0.83  0.62      0.76       0.72          0.76\n",
            "support   151.00 80.00      0.76     231.00        231.00\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "estimators = []\n",
        "log_reg = LogisticRegression(solver='liblinear')\n",
        "estimators.append(('Logistic', log_reg))\n",
        "\n",
        "tree = DecisionTreeClassifier()\n",
        "estimators.append(('Tree', tree))\n",
        "\n",
        "svm_clf = SVC(gamma='scale')\n",
        "estimators.append(('SVM', svm_clf))\n",
        "\n",
        "voting = VotingClassifier(estimators=estimators)\n",
        "voting.fit(X_train, y_train)\n",
        "\n",
        "evaluate(voting, X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:33.410344Z",
          "iopub.status.busy": "2022-02-05T22:49:33.409886Z",
          "iopub.status.idle": "2022-02-05T22:49:33.440069Z",
          "shell.execute_reply": "2022-02-05T22:49:33.439336Z",
          "shell.execute_reply.started": "2022-02-05T22:49:33.410288Z"
        },
        "id": "XxnE_7btu_hY"
      },
      "outputs": [],
      "source": [
        "scores['Voting'] = {\n",
        "        'Train': accuracy_score(y_train, voting.predict(X_train)),\n",
        "        'Test': accuracy_score(y_test, voting.predict(X_test)),\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHNwi2E3u_hZ"
      },
      "source": [
        "# Model Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-05T22:49:33.441706Z",
          "iopub.status.busy": "2022-02-05T22:49:33.441251Z",
          "iopub.status.idle": "2022-02-05T22:49:33.737347Z",
          "shell.execute_reply": "2022-02-05T22:49:33.736549Z",
          "shell.execute_reply.started": "2022-02-05T22:49:33.441632Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "zbkDK279u_hb",
        "outputId": "1b7ccf2b-988c-4e24-e0fa-130eb4963846"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa099203e10>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "scores_df = pd.DataFrame(scores)\n",
        "\n",
        "scores_df.plot(kind='barh', figsize=(15, 8))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "ex6.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}